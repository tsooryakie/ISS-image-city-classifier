"""
This is the main program for training transfer learning architectures on the ISS imagery dataset.
It supports training ResNet-101, ResNet-152, VGG-19 and Inception V3.
Version: 19/07/2020
"""
import copy
import os
import sys
import time
from typing import Tuple, Dict, List

import PIL
import matplotlib.pyplot as plt
import numpy as np
import toml
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision as vision
from torch.utils.data import DataLoader

import augmentation_visualisation as vis_augment
from image_augmentation import Augmentation


def load_dataset_and_transforms(
    dataset_path: str, uses_inception: bool, batch_size: int, augment: bool
) -> Tuple[Dict, List]:
    """
    This function loads the dataset, applies transformations to the images and creates
    the data loader which is used in the training step to train the CNN.
    :param dataset_path: Path to the dataset to use for training and validation
    :param batch_size: Batch size to use for training (number of training samples used per training iteration)
    :param uses_inception: Pre-trained InceptionV3 model has different input and an auxiliary outputs,
    hence it must be treated differently to other models used (e.g. VGG19 or ResNet-101)
    :param augment: If true, creates an instance of Augmentation class and applies the augmentations to transforms
    :return: data_loader and classes - The data loader used to train the network and the number of classes
    """

    if uses_inception:
        input_size = 299  # InceptionV3 input size is 299x299 pixels
    else:
        input_size = 224  # Other network architectures pre-trained on ImageNet have input size of 224x224 pixels

    if augment:
        augmentations = (
            Augmentation()
        )  # Creates an instance of Augmentation class with relevant transformations
        transformations = {
            "train": vision.transforms.Compose(
                [
                    augmentations,  # Augmentations should only be applied to the training dataset
                    lambda x: PIL.Image.fromarray(
                        x
                    ),  # Augmentations must be converted to PIL images to work with PyTorch
                    vision.transforms.CenterCrop(input_size),
                    vision.transforms.ToTensor(),
                    vision.transforms.Normalize(
                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                    ),  # ImageNet normalisation
                ]
            ),
            "validation": vision.transforms.Compose(
                [
                    vision.transforms.CenterCrop(input_size),
                    vision.transforms.ToTensor(),
                    vision.transforms.Normalize(
                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                    ),  # ImageNet normalisation
                ]
            ),
        }
    else:
        transformations = {
            "train": vision.transforms.Compose(
                [
                    vision.transforms.CenterCrop(input_size),
                    vision.transforms.ToTensor(),
                    vision.transforms.Normalize(
                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                    ),  # ImageNet normalisation
                ]
            ),
            "validation": vision.transforms.Compose(
                [
                    vision.transforms.CenterCrop(input_size),
                    vision.transforms.ToTensor(),
                    vision.transforms.Normalize(
                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                    ),  # ImageNet normalisation
                ]
            ),
        }

    image_dataset = {
        image: vision.datasets.ImageFolder(
            os.path.join(dataset_path, image), transformations[image]
        )
        for image in ["train", "validation"]
    }

    data_loader = {
        image: DataLoader(
            image_dataset[image], batch_size=batch_size, shuffle=True, num_workers=4
        )
        for image in ["train", "validation"]
    }

    classes = image_dataset["train"].classes

    return data_loader, classes


def train_model(
    model, data_loader, device, criterion, optimizer, model_name, uses_inception, epochs
):
    """
    This function begins training of the model. It takes a model pre-trained on ImageNet and
    retrains the model on the night time ISS imagery dataset. The model keeps track of
    training and validation accuracy and loss over training period and at the end
    returns the best trained model weights.
    :param model: Model to use, in this case: InceptionV3, VGG19, ResNet-101
    :param data_loader: Data loader generated by the load_dataset_and_transforms() function
    :param device: Device used for training, will be either GPU or CPU.
    :param criterion: Loss Function - e.g. Cross Entropy Loss
    :param optimizer: Algorithm for calculating Gradient Descent - e.g. Adam, RMSProp or SGD
    :param model_name: Model name from standard input
    :param epochs: Number of epochs to train the model for, e.g. 30
    :param uses_inception: Checks whether the model being trained is InceptionV3.
    :return: model, history - The trained model weights and dictionary of training history
    """
    training_start_time = time.time()  # Gets time when training started

    best_model_weights = copy.deepcopy(
        model.state_dict()
    )  # Initialises model with ImageNet weights

    best_accuracy = 0.0  # Initialises Accuracy variable with 0

    # Early stopping variables
    best_loss = np.inf
    validation_loss_not_improving = 0
    patience = 20

    # Initialises empty lists to which accuracy and loss of each phase per epoch will be appended
    training_accuracy_history = []
    validation_accuracy_history = []
    training_loss_history = []
    validation_loss_history = []

    for epoch in range(1, epochs + 1):
        print("Epoch: " + str(epoch) + "/" + str(epochs))
        if validation_loss_not_improving == patience:
            break

        for phase in ["train", "validation"]:
            if phase == "train":
                model.train()
            else:
                model.eval()

            current_loss = 0.0
            current_correct = 0

            for inputs, labels in data_loader[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()  # Clears the old gradients from the last step by setting them to equal zero

                with torch.set_grad_enabled(phase == "train"):
                    if uses_inception and phase == "train":
                        outputs, auxiliary_outputs = model(
                            inputs
                        )  # Forward pass over network - computes outputs
                        loss1 = criterion(outputs, labels)
                        loss2 = criterion(auxiliary_outputs, labels)
                        loss = loss1 + (
                            0.4 * loss2
                        )  # Auxiliary loss function (Loss2) is weighted less than Loss1
                        # Weighing at 0.4 seems to be optimal
                    else:
                        outputs = model(inputs)
                        loss = criterion(outputs, labels)

                    dummy, predictions = torch.max(outputs, 1)

                    if phase == "train":
                        loss.backward()  # Backpropagation - Calculates partial derivative of loss function WRT weights
                        optimizer.step()  # Optimizer takes a step based on the gradient calculated by Backpropagation

                current_loss += loss.item() * inputs.size(0)
                current_correct += torch.sum(predictions == labels.data)

            training_loss = current_loss / len(data_loader["train"].dataset)
            training_accuracy = current_correct.double() / len(
                data_loader["train"].dataset
            )
            validation_loss = current_loss / len(data_loader["validation"].dataset)
            validation_accuracy = current_correct.double() / len(
                data_loader["validation"].dataset
            )

            if phase == "train":
                training_accuracy_history.append(training_accuracy)
                training_loss_history.append(training_loss)
                print(
                    "Training Loss: {:.4f}, Accuracy: {:.4f}".format(
                        training_loss, training_accuracy
                    )
                )
            else:
                validation_accuracy_history.append(validation_accuracy)
                validation_loss_history.append(validation_loss)
                print(
                    "Validation Loss: {:.4f}, Accuracy: {:.4f}".format(
                        validation_loss, validation_accuracy
                    )
                )

            if phase == "validation" and validation_accuracy > best_accuracy:
                best_accuracy = validation_accuracy
                best_model_weights = copy.deepcopy(model.state_dict())

            if phase == "validation" and validation_loss < best_loss:
                print(
                    "Validation loss has improved from: "
                    + str(best_loss)
                    + " to: "
                    + str(validation_loss)
                )
                validation_loss_not_improving = 0
                best_loss = validation_loss
            elif phase == "validation" and validation_loss > best_loss:
                print("Validation loss has not improved during this epoch.")
                validation_loss_not_improving += 1
                print(
                    "Number of epochs where validation loss has not improved is now: "
                    + str(validation_loss_not_improving)
                )
            else:
                pass

            if validation_loss_not_improving == patience:
                print(
                    "Validation loss has not improved for "
                    + str(patience)
                    + " iterations. Stopping Training"
                )
                break

    time_elapsed = time.time() - training_start_time
    print(
        "Training complete in {:.0f}m {:.0f}s".format(
            time_elapsed // 60, time_elapsed % 60
        )
    )
    print("Best Validation Accuracy: {:4f}".format(best_accuracy))

    model.load_state_dict(best_model_weights)
    torch.save(model.state_dict(), "models_trained/" + model_name + "_model.pth")

    # Training history dictionary for the plotting function
    history = {
        "train_acc": training_accuracy_history,
        "train_loss": training_loss_history,
        "val_acc": validation_accuracy_history,
        "val_loss": validation_loss_history,
    }

    return model, history


def freeze_layers(model, freeze_all):
    """
    This function iterates through the model's layers
    and sets the trainability of the layers to false if the "freeze_all" argument is True.
    :param model: Model whose layers are to be frozen
    :param freeze_all: True to freeze all layers, false otherwise
    :return:
    """
    if freeze_all:
        for param in model.parameters():
            param.requires_grad = False
    else:
        for param in model.parameters():
            param.requires_grad = True

    return


def initialise_model(model_name, num_classes, freeze_all):
    """
    This function initialises the chosen model in order to make the model be ready
    to be supplied to the training function.
    :param model_name: Model to initialise, can be "inception", "vgg19" or "resnet"
    :param num_classes: Number of classes in the classification problem
    :param freeze_all: Model Parameters to freeze
    :return: Initialised model and input size of the model
    """
    if model_name == "InceptionV3":
        """
        InceptionV3 Initialisation
        """
        model = vision.models.inception_v3(pretrained=True)
        freeze_layers(model, freeze_all=freeze_all)
        input_size = 299

        # Auxiliary Outputs Initialisation:
        aux_features = model.AuxLogits.fc.in_features
        model.AuxLogits.fc = nn.Linear(aux_features, num_classes)

        # Main Outputs Initialisation
        main_features = model.fc.in_features
        model.fc = nn.Linear(main_features, num_classes)

    elif model_name == "VGG-19_BN":
        """
        VGG19 With Batch Normalisation Initialisation
        """
        model = vision.models.vgg19_bn(pretrained=True)
        freeze_layers(model, freeze_all=freeze_all)
        input_size = 224
        num_features = model.classifier[6].in_features
        model.classifier[6] = nn.Linear(num_features, num_classes)

    elif model_name == "ResNet-101":
        """
        ResNet-101 Initialisation
        """
        model = vision.models.resnet101(pretrained=True)
        freeze_layers(model, freeze_all=freeze_all)
        input_size = 224
        num_features = model.fc.in_features
        model.fc = nn.Linear(num_features, num_classes)

    elif model_name == "ResNet-152":
        """
        ResNet-152 Initialisation
        """
        model = vision.models.resnet152(pretrained=True)
        freeze_layers(model, freeze_all=freeze_all)
        input_size = 224
        num_features = model.fc.in_features
        model.fc = nn.Linear(num_features, num_classes)

    else:
        raise ValueError("model_name parameter received an unsupported model name")

    return model, input_size


def get_parameters_to_learn(model, training_mode):
    """
    This function extracts model parameters to learn and checks
    whether the parameter weights should be trained or not.
    :param model: Model from which parameters are extracted
    :param training_mode: Feature extraction or Fine tuning
    :return:
    """
    parameters_to_learn = model.parameters()
    print("Parameters to learn: ")
    if training_mode == "feature_extraction":
        parameters_to_learn = []
        for name, parameter in model.named_parameters():
            if parameter.requires_grad:
                parameters_to_learn.append(parameter)
                print(name)
    elif training_mode == "finetuning":
        parameters_to_learn = []
        for name, parameter in model.named_parameters():
            if parameter.requires_grad:
                parameters_to_learn.append(parameter)
                print(name)
    else:
        raise ValueError("Incompatible Training Mode argument supplied.")

    return parameters_to_learn


def plot_model_history(
    history_dictionary, model_name, learning_rate, batch_size, optimizer, weight_decay
):
    """
    This function plots the model training and validation accuracy as well as
    the training and validation losses. It then saves the resulting graphs to the "visualisations"
    directory.
    :return:
    """
    plt.style.use("ggplot")

    if model_name == "InceptionV3":
        model_name_title = "Inception V3"
    elif model_name == "VGG_19_BN":
        model_name_title = "VGG-19 with Batch Norm."
    else:
        model_name_title = model_name

    num_epochs = len(history_dictionary["train_acc"])

    plt.figure()
    plt.plot(
        range(num_epochs),
        [i * 100 for i in history_dictionary["train_acc"]],
        color="red",
    )
    plt.plot(
        range(num_epochs),
        [i * 100 for i in history_dictionary["val_acc"]],
        color="green",
    )
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy (%)")
    plt.title("Training and Validation Accuracy on " + model_name_title)
    plt.legend(["Training Accuracy", "Validation Accuracy"])
    plt.savefig(
        "../visualisations/model_training/"
        + model_name
        + "_training_validation_acc.png"
    )

    plt.figure()
    plt.plot(range(num_epochs), history_dictionary["train_loss"], color="red")
    plt.plot(range(num_epochs), history_dictionary["val_loss"], color="green")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title(
        "Training and Validation Loss on "
        + model_name_title
        + "\n LR: "
        + str(learning_rate)
        + " BS: "
        + str(batch_size)
        + " Optim: "
        + str(optimizer)
        + " WD: "
        + str(weight_decay)
    )
    plt.legend(["Training Loss", "Validation Loss"])
    plt.savefig(
        "../visualisations/model_training/"
        + model_name
        + "_training_validation_loss.png"
    )

    return


def main():
    model_name = sys.argv[1]

    config = toml.load("training_config.toml")

    if model_name == "InceptionV3":
        uses_inception = True
    else:
        uses_inception = False

    data_loaders, classes = load_dataset_and_transforms(
        "../iss_image_data/experiment3/",
        uses_inception,
        augment=True,
        batch_size=config["batch_size"],
    )
    vis_augment.visualise_augmented_images(data_loaders, classes)

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("Device being used for training: " + str(device))
    model, input_size = initialise_model(model_name, len(classes), freeze_all=False)
    parameters_to_learn = get_parameters_to_learn(
        model, training_mode=config["training_mode"]
    )
    model = model.to(device)

    optimizer = optim.Adam(
        parameters_to_learn,
        lr=config["learning_rate"],
        weight_decay=config["weight_decay"],
    )
    criterion = nn.CrossEntropyLoss()

    print("\nStarting model training...")
    model, history = train_model(
        model,
        data_loaders,
        device,
        criterion,
        optimizer,
        model_name,
        uses_inception,
        epochs=config["epochs"],
    )

    # Extra variables for plotting
    learning_rate = config["learning_rate"]
    batch_size = config["batch_size"]
    optimizer_name = config["optimizer_name"]
    weight_decay = config["weight_decay"]
    plot_model_history(
        history, model_name, learning_rate, batch_size, optimizer_name, weight_decay
    )

    return


if __name__ == "__main__":
    main()
